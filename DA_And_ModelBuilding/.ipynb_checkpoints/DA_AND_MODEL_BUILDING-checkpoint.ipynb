{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21ba7adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fba8d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading DataSet\n",
    "dataset=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90aa746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping unnecessary columns\n",
    "dataset=dataset.drop(columns=['Dev_ID','Geographic_Regions','Gender','Age','Project_Age','Dev_Status','Education','Expt_Het'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7751d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Int_Learn</th>\n",
       "      <th>Fin_Gain</th>\n",
       "      <th>Tech_Cont_Norm</th>\n",
       "      <th>Sys_Int</th>\n",
       "      <th>Cod_Test_Task</th>\n",
       "      <th>Cont_Code_Dec</th>\n",
       "      <th>Dec_Right_Dec</th>\n",
       "      <th>Dev_Inv</th>\n",
       "      <th>Proj_Desertion</th>\n",
       "      <th>Promoted</th>\n",
       "      <th>Dev_Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.67</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.67</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.83</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.67</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.33</td>\n",
       "      <td>6.50</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.00</td>\n",
       "      <td>5.50</td>\n",
       "      <td>4.67</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Int_Learn  Fin_Gain  Tech_Cont_Norm  Sys_Int  Cod_Test_Task  Cont_Code_Dec  \\\n",
       "0       6.00      5.00            4.67     5.50            4.8            3.8   \n",
       "1       5.67      4.75            4.50     4.75            4.6            4.0   \n",
       "2       6.67      6.50            4.83     6.00            6.2            5.4   \n",
       "3       5.67      5.75            5.33     6.50            3.8            1.8   \n",
       "4       5.00      5.50            4.67     5.00            4.2            3.2   \n",
       "\n",
       "   Dec_Right_Dec  Dev_Inv  Proj_Desertion  Promoted  Dev_Experience  \n",
       "0            4.2      4.0             7.0         0               1  \n",
       "1            3.6      6.2             2.4         1               5  \n",
       "2            3.6      6.8             4.0         0               1  \n",
       "3            2.2      7.0             1.4         1               1  \n",
       "4            4.2      4.4             3.8         0               2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69cdf01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Int_Learn', 'Fin_Gain', 'Tech_Cont_Norm', 'Sys_Int', 'Cod_Test_Task',\n",
       "       'Cont_Code_Dec', 'Dec_Right_Dec', 'Dev_Inv', 'Proj_Desertion',\n",
       "       'Promoted', 'Dev_Experience'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing all the column names for our reference\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b427446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Int_Learn', 'Fin_Gain', 'Tech_Cont_Norm', 'Sys_Int', 'Cod_Test_Task', 'Cont_Code_Dec', 'Dec_Right_Dec', 'Dev_Inv', 'Proj_Desertion', 'Dev_Experience']\n"
     ]
    }
   ],
   "source": [
    "# Separate Target Variable and Predictor Variables\n",
    "TargetVariable='Promoted'\n",
    "Predictors=[i for i in dataset.columns if i not in TargetVariable]\n",
    "print(Predictors)\n",
    "X=dataset[Predictors].values\n",
    "y=dataset[TargetVariable].values\n",
    "\n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=428)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99a81044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 10) (52, 10) (121,) (52,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ded24d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sandardization of data ###\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# Choose either standardization or Normalization\n",
    "# On this data Min Max Normalization produced better results\n",
    "\n",
    "# Choose between standardization and MinMAx normalization\n",
    "#PredictorScaler=StandardScaler()\n",
    "PredictorScaler=MinMaxScaler()\n",
    "\n",
    "# Storing the fit object for later reference\n",
    "PredictorScalerFit=PredictorScaler.fit(X)\n",
    "\n",
    "# Generating the standardized values of X\n",
    "X=PredictorScalerFit.transform(X)\n",
    "\n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e388fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121, 10) (52, 10) (121,) (52,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "831a08c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        45\n",
      "           1       0.75      0.43      0.55         7\n",
      "\n",
      "    accuracy                           0.90        52\n",
      "   macro avg       0.83      0.70      0.75        52\n",
      "weighted avg       0.89      0.90      0.89        52\n",
      "\n",
      "[[44  1]\n",
      " [ 4  3]]\n",
      "Accuracy of the model on Testing Sample Data: 0.89\n",
      "\n",
      "Accuracy values for 10-fold Cross Validation:\n",
      " [0.75757576 0.86458333 0.86458333 0.82720588 0.93232132 0.82720588\n",
      " 0.80892495 0.85686275 0.71372549 1.        ]\n",
      "\n",
      "Final Average Accuracy of the model: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# choose parameter Penalty='l1' or C=1\n",
    "# choose different values for solver 'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'\n",
    "clf = LogisticRegression(C=1,penalty='l2', solver='newton-cg')\n",
    "\n",
    "# Printing all the parameters of logistic regression\n",
    "# print(clf)\n",
    "\n",
    "# Creating the model on Training Data\n",
    "LOG=clf.fit(X_train,y_train)\n",
    "prediction_log=LOG.predict(X_test)\n",
    "\n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction_log))\n",
    "print(metrics.confusion_matrix(y_test, prediction_log))\n",
    "\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction_log, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(LOG, X , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "093069f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        45\n",
      "           1       0.70      1.00      0.82         7\n",
      "\n",
      "    accuracy                           0.94        52\n",
      "   macro avg       0.85      0.97      0.89        52\n",
      "weighted avg       0.96      0.94      0.95        52\n",
      "\n",
      "[[42  3]\n",
      " [ 0  7]]\n",
      "Accuracy of the model on Testing Sample Data: 0.95\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy of the model on Testing Sample Data:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mround\u001b[39m(F1_Score,\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Plotting the feature importance for Top 10 most important columns\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(DTree\u001b[38;5;241m.\u001b[39mfeature_importances_, index\u001b[38;5;241m=\u001b[39mPredictors)\n\u001b[0;32m     25\u001b[0m feature_importances\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbarh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\OurProject2022\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2309\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2307\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2309\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Desktop\\OurProject2022\\env\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m backends_list)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[1;32m~\\Desktop\\OurProject2022\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3458\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   3437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menable_matplotlib\u001b[39m(\u001b[38;5;28mself\u001b[39m, gui\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3438\u001b[0m     \u001b[38;5;124;03m\"\"\"Enable interactive matplotlib and inline figure support.\u001b[39;00m\n\u001b[0;32m   3439\u001b[0m \n\u001b[0;32m   3440\u001b[0m \u001b[38;5;124;03m    This takes the following steps:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3456\u001b[0m \u001b[38;5;124;03m        display figures inline.\u001b[39;00m\n\u001b[0;32m   3457\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3458\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_inline_support\n\u001b[0;32m   3460\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[0;32m   3461\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n",
      "File \u001b[1;32m~\\Desktop\\OurProject2022\\env\\lib\\site-packages\\matplotlib_inline\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_inline, config  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\OurProject2022\\env\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) IPython Development Team.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colors\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_agg\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "#Decision Trees\n",
    "from sklearn import tree\n",
    "#choose from different tunable hyper parameters\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Printing all the parameters of Decision Trees\n",
    "print(clf)\n",
    "\n",
    "# Creating the model on Training Data\n",
    "DTree=clf.fit(X_train,y_train)\n",
    "prediction_DT=DTree.predict(X_test)\n",
    "\n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction_DT))\n",
    "print(metrics.confusion_matrix(y_test, prediction_DT))\n",
    "\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction_DT, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Plotting the feature importance for Top 10 most important columns\n",
    "%matplotlib inline\n",
    "feature_importances = pd.Series(DTree.feature_importances_, index=Predictors)\n",
    "feature_importances.nlargest(10).plot(kind='barh')\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(DTree, X , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62c070de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tree\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      4\u001b[0m tree\u001b[38;5;241m.\u001b[39mplot_tree(clf,filled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "tree.plot_tree(clf,filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69271d18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.04444444, 1.        ]),\n",
       " array([0., 1., 1.]),\n",
       " array([2, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "roc_curve(y_test, prediction_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77171e64",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [30], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m logistic_fpr, logistic_tpr, threshold \u001b[38;5;241m=\u001b[39m roc_curve(y_test, prediction_log)\n\u001b[0;32m      7\u001b[0m auc_logistic \u001b[38;5;241m=\u001b[39m auc(logistic_fpr, logistic_tpr)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m), dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(DT_fpr, DT_tpr, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDT (auc = \u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m auc_DT)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(logistic_fpr, logistic_tpr, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogistic (auc = \u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m auc_logistic)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "DT_fpr, DT_tpr, threshold = roc_curve(y_test, prediction_DT)\n",
    "auc_DT = auc(DT_fpr,DT_tpr)\n",
    "\n",
    "logistic_fpr, logistic_tpr, threshold = roc_curve(y_test, prediction_log)\n",
    "auc_logistic = auc(logistic_fpr, logistic_tpr)\n",
    "\n",
    "plt.figure(figsize=(5, 5), dpi=100)\n",
    "plt.plot(DT_fpr, DT_tpr, linestyle='-', label='DT (auc = %0.3f)' % auc_DT)\n",
    "plt.plot(logistic_fpr, logistic_tpr, marker='.', label='Logistic (auc = %0.3f)' % auc_logistic)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive Rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bad5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning for decision tree\n",
    "params={\n",
    " \"splitter\"    : [\"best\",\"random\"] ,\n",
    "    \"criterion\":['gini','entropy'],\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_samples_leaf\" : [ 1,2,3,4,5 ],\n",
    "\"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4],\n",
    " \"max_features\" : [\"auto\",\"log2\",\"sqrt\",None ],\n",
    "    \"max_leaf_nodes\":[None,10,20,30,40,50,60,70]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d043e1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20480 candidates, totalling 102400 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5, 6, 8, 10, 12, 15],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;log2&#x27;, &#x27;sqrt&#x27;, None],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [None, 10, 20, 30, 40, 50, 60, 70],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0.1, 0.2, 0.3, 0.4],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5, 6, 8, 10, 12, 15],\n",
       "                         &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;log2&#x27;, &#x27;sqrt&#x27;, None],\n",
       "                         &#x27;max_leaf_nodes&#x27;: [None, 10, 20, 30, 40, 50, 60, 70],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 3, 4, 5],\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: [0.1, 0.2, 0.3, 0.4],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [3, 4, 5, 6, 8, 10, 12, 15],\n",
       "                         'max_features': ['auto', 'log2', 'sqrt', None],\n",
       "                         'max_leaf_nodes': [None, 10, 20, 30, 40, 50, 60, 70],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       "                         'min_weight_fraction_leaf': [0.1, 0.2, 0.3, 0.4],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Hyperparameter optimization using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier()\n",
    "\n",
    "random_search=GridSearchCV(dtree,param_grid=params,scoring='f1_weighted',n_jobs=-1,cv=5,verbose=3)\n",
    "random_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83dd88a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 3,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': 60,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_weight_fraction_leaf': 0.1,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb1f00e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416459076985394"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f976499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(criterion='entropy', max_depth=10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95        45\n",
      "           1       0.67      0.57      0.62         7\n",
      "\n",
      "    accuracy                           0.90        52\n",
      "   macro avg       0.80      0.76      0.78        52\n",
      "weighted avg       0.90      0.90      0.90        52\n",
      "\n",
      "[[43  2]\n",
      " [ 3  4]]\n",
      "Accuracy of the model on Testing Sample Data: 0.9\n",
      "\n",
      "Accuracy values for 10-fold Cross Validation:\n",
      " [1.         0.86458333 0.94745484 0.88235294 0.88235294 0.88235294\n",
      " 0.88235294 0.93630832 0.88235294 0.93630832]\n",
      "\n",
      "Final Average Accuracy of the model: 0.91\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFinal Average Accuracy of the model:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mround\u001b[39m(Accuracy_Values\u001b[38;5;241m.\u001b[39mmean(),\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Plotting the feature importance for Top 4 most important columns\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(RF\u001b[38;5;241m.\u001b[39mfeature_importances_, index\u001b[38;5;241m=\u001b[39mPredictors)\n\u001b[0;32m     36\u001b[0m feature_importances\u001b[38;5;241m.\u001b[39mnlargest(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbarh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\OurProject2022\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2309\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2307\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2309\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Desktop\\OurProject2022\\env\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:99\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m backends_list)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[1;32m~\\Desktop\\OurProject2022\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3458\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   3437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menable_matplotlib\u001b[39m(\u001b[38;5;28mself\u001b[39m, gui\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3438\u001b[0m     \u001b[38;5;124;03m\"\"\"Enable interactive matplotlib and inline figure support.\u001b[39;00m\n\u001b[0;32m   3439\u001b[0m \n\u001b[0;32m   3440\u001b[0m \u001b[38;5;124;03m    This takes the following steps:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3456\u001b[0m \u001b[38;5;124;03m        display figures inline.\u001b[39;00m\n\u001b[0;32m   3457\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3458\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_inline_support\n\u001b[0;32m   3460\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[0;32m   3461\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n",
      "File \u001b[1;32m~\\Desktop\\OurProject2022\\env\\lib\\site-packages\\matplotlib_inline\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_inline, config  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\Desktop\\OurProject2022\\env\\lib\\site-packages\\matplotlib_inline\\backend_inline.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"A matplotlib backend for publishing figures via display_data\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) IPython Development Team.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Distributed under the terms of the BSD 3-Clause License.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colors\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_agg\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Random Forest (Bagging of multiple Decision Trees)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Choose various values of max_depth, n_estimators and criterion for tuning the model\n",
    "random = RandomForestClassifier(max_depth=10, n_estimators=100,criterion='entropy')\n",
    "\n",
    "\n",
    "# Printing all the parameters of Random Forest\n",
    "print(random)\n",
    "\n",
    "# Creating the model on Training Data\n",
    "RF=random.fit(X_train,y_train)\n",
    "prediction_RF=RF.predict(X_test)\n",
    "\n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction_RF))\n",
    "print(metrics.confusion_matrix(y_test, prediction_RF))\n",
    "\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction_RF, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(RF, X , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))\n",
    "\n",
    "\n",
    "# Plotting the feature importance for Top 4 most important columns\n",
    "%matplotlib inline\n",
    "feature_importances = pd.Series(RF.feature_importances_, index=Predictors)\n",
    "feature_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac5ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "roc_curve(y_test, prediction_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "RF_fpr, RF_tpr, threshold = roc_curve(y_test, prediction_RF)\n",
    "auc_RF = auc(RF_fpr,RF_tpr)\n",
    "\n",
    "decision_fpr, decision_tpr, threshold = roc_curve(y_test, prediction_DT)\n",
    "auc_decision = auc(decision_fpr, decision_tpr)\n",
    "\n",
    "plt.figure(figsize=(5, 5), dpi=100)\n",
    "plt.plot(RF_fpr, RF_tpr, linestyle='-', label='RF (auc = %0.3f)' % auc_RF)\n",
    "plt.plot(decision_fpr, decision_tpr, marker='.', label='DT (auc = %0.3f)' % auc_decision)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive Rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682404ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Choosing Decision Tree with 1 level as the weak learner\n",
    "# Choose different values of max_depth, n_estimators and learning_rate to tune the model\n",
    "DTC=DecisionTreeClassifier(max_depth=4)\n",
    "clf = AdaBoostClassifier(n_estimators=200, base_estimator=DTC ,learning_rate=0.01)\n",
    "\n",
    "# Printing all the parameters of Adaboost\n",
    "print(clf)\n",
    "\n",
    "# Creating the model on Training Data\n",
    "AB=clf.fit(X_train,y_train)\n",
    "prediction_AB=AB.predict(X_test)\n",
    "\n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction_AB))\n",
    "print(metrics.confusion_matrix(y_test, prediction_AB))\n",
    "\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction_AB, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(AB, X , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))\n",
    "\n",
    "# Plotting the feature importance for Top 10 most important columns\n",
    "%matplotlib inline\n",
    "feature_importances = pd.Series(AB.feature_importances_, index=Predictors)\n",
    "feature_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c79fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "roc_curve(y_test, prediction_AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "AB_fpr, AB_tpr, threshold = roc_curve(y_test, prediction_AB)\n",
    "auc_AB = auc(AB_fpr,AB_tpr)\n",
    "\n",
    "randomForest_fpr, randomForest_tpr, threshold = roc_curve(y_test, prediction_RF)\n",
    "auc_randomForest = auc(randomForest_fpr, randomForest_tpr)\n",
    "\n",
    "plt.figure(figsize=(5, 5), dpi=100)\n",
    "plt.plot(AB_fpr, AB_tpr, linestyle='-', label='AB (auc = %0.3f)' % auc_AB)\n",
    "plt.plot(logistic_fpr, logistic_tpr, marker='.', label='RF (auc = %0.3f)' % auc_logistic)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive Rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xtreme Gradient Boosting (XGBoost)\n",
    "from xgboost import XGBClassifier\n",
    "clf=XGBClassifier(max_depth=10, learning_rate=0.01, n_estimators=200, objective='binary:logistic', booster='gbtree')\n",
    "\n",
    "# Printing all the parameters of XGBoost\n",
    "print(clf)\n",
    "\n",
    "# Creating the model on Training Data\n",
    "XGB=clf.fit(X_train,y_train)\n",
    "prediction_XGB=XGB.predict(X_test)\n",
    "\n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction_XGB))\n",
    "print(metrics.confusion_matrix(y_test, prediction_XGB))\n",
    "\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction_XGB, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(XGB, X , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))\n",
    "\n",
    "# Plotting the feature importance for Top 10 most important columns\n",
    "%matplotlib inline\n",
    "feature_importances = pd.Series(XGB.feature_importances_, index=Predictors)\n",
    "feature_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "params={\n",
    " \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
    "    \n",
    "}\n",
    "## Hyperparameter optimization using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import xgboost\n",
    "\n",
    "\n",
    "clf=xgboost.XGBClassifier()\n",
    "random_search=RandomizedSearchCV(clf,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)\n",
    "\n",
    "random_search.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=xgboost.XGBClassifier(base_score=0.5, colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=10, min_child_weight=5, booster='gbtree',max_delta_step=0,n_estimators=200, n_jobs=1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6842fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score=cross_val_score(classifier,X,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a667d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB=classifier.fit(X_train,y_train)\n",
    "prediction_XGB=XGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction_XGB))\n",
    "print(metrics.confusion_matrix(y_test, prediction_XGB))\n",
    "\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction_XGB, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(XGB, X , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))\n",
    "\n",
    "# Plotting the feature importance for Top 4 most important columns\n",
    "%matplotlib inline\n",
    "feature_importances = pd.Series(XGB.feature_importances_, index=Predictors)\n",
    "feature_importances.nlargest(4).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "XGB_fpr, XGB_tpr, threshold = roc_curve(y_test, prediction_XGB)\n",
    "auc_XGB = auc(XGB_fpr,XGB_tpr)\n",
    "\n",
    "AB_fpr, AB_tpr, threshold = roc_curve(y_test, prediction_AB)\n",
    "auc_AB = auc(AB_fpr, AB_tpr)\n",
    "\n",
    "plt.figure(figsize=(5, 5), dpi=100)\n",
    "plt.plot(XGB_fpr, XGB_tpr, linestyle='-', label='XGB (auc = %0.3f)' % auc_XGB)\n",
    "plt.plot(AB_fpr, AB_tpr, marker='.', label='AB (auc = %0.3f)' % auc_AB)\n",
    "\n",
    "plt.xlabel('False Positive Rate -->')\n",
    "plt.ylabel('True Positive Rate -->')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182678d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56659d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bays\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "\n",
    "# GaussianNB is used in Binomial Classification\n",
    "# MultinomialNB is used in multi-class classification\n",
    "clfNaive = GaussianNB()\n",
    "#clf = MultinomialNB()\n",
    "\n",
    "# Printing all the parameters of Naive Bayes\n",
    "print(clfNaive)\n",
    "\n",
    "NB=clfNaive.fit(X_train,y_train)\n",
    "prediction_NB=NB.predict(X_test)\n",
    "\n",
    "# Measuring accuracy on Testing Data\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, prediction_NB))\n",
    "print(metrics.confusion_matrix(y_test, prediction_NB))\n",
    "\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=metrics.f1_score(y_test, prediction_NB, average='weighted')\n",
    "print('Accuracy of the model on Testing Sample Data:', round(F1_Score,2))\n",
    "\n",
    "# Importing cross validation function from sklearn\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Running 10-Fold Cross validation on a given algorithm\n",
    "# Passing full data X and y because the K-fold will split the data and automatically choose train/test\n",
    "Accuracy_Values=cross_val_score(NB, X , y, cv=10, scoring='f1_weighted')\n",
    "print('\\nAccuracy values for 10-fold Cross Validation:\\n',Accuracy_Values)\n",
    "print('\\nFinal Average Accuracy of the model:', round(Accuracy_Values.mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbae309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the test data\n",
    "test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67192c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf530ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping unnecessary columns\n",
    "testData=test.drop(columns=['Dev_ID','Geographic_Regions','Gender','Age','Project_Age','Dev_Status','Education','Expt_Het'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c13b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "testData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping Copy of datset for future reference\n",
    "mainTestData=testData.copy()\n",
    "#Calculation Missing VAlues in indivisual column\n",
    "testData.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5988d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Retraining the model using 100% data\n",
    "# XGBoost \n",
    "import xgboost\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Using the XGBoost algorithm with final hyperparamters\n",
    "classifier=xgboost.XGBClassifier(base_score=0.5, colsample_bytree=0.7, gamma=0.3, learning_rate=0.1, max_depth=10, min_child_weight=5, booster='gbtree',max_delta_step=0,n_estimators=200, n_jobs=1, nthread=None,\n",
    "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1)\n",
    "\n",
    "# Training the model on 100% Data available\n",
    "FinalXGBModel=classifier.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Save the model as a serialized file which can be stored anywhere\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Saving the Python objects as serialized files can be done using pickle library\n",
    "# Here let us save the Final ZomatoRatingModel\n",
    "with open('FinalXGBModel.pkl', 'wb') as fileWriteStream:\n",
    "    pickle.dump(FinalXGBModel, fileWriteStream)\n",
    "    # Don't forget to close the filestream!\n",
    "    fileWriteStream.close()\n",
    "    \n",
    "print('pickle file of Predictive Model is saved at Location:',os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb30ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Function can be called from any from any front end tool/website\n",
    "def predict_promotion(test):\n",
    "    DataSet=test\n",
    "    #Avoidng Dumy Trap for applying Drop First\n",
    "    DataSet=pd.get_dummies(DataSet,drop_first=True)\n",
    "    # Maintaining the same order of columns as it was during the model training\n",
    "    Num_Inputs = DataSet.shape[0]\n",
    "    print(Num_Inputs)\n",
    "    Predictors=['Int_Learn','Fin_Gain','Tech_Cont_Norm','Sys_Int','Cod_Test_Task','Cont_Code_Dec', 'Dec_Right_Dec','Dev_Inv', 'Proj_Desertion','Dev_Experience']\n",
    "    X=DataSet[Predictors].values\n",
    "    X=PredictorScalerFit.transform(X)\n",
    "    print(X)\n",
    "    # Loading the Function from pickle file\n",
    "    import pickle\n",
    "    with open('FinalXGBModel.pkl', 'rb') as fileReadStream:\n",
    "        XGB_model=pickle.load(fileReadStream)\n",
    "        # Don't forget to close the filestream!\n",
    "        fileReadStream.close()\n",
    "        \n",
    "    # Genrating Predictions\n",
    "    Prediction=XGB_model.predict(X)\n",
    "    PredictedStatus=pd.DataFrame(Prediction, columns=['Predicted Status'])\n",
    "    \n",
    "    return(PredictedStatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_promotion(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a53724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
